# ASR-for-clean-and-noisy-speech
ASR for clean and noisy speech

A prominent problem in speech recognition is how to deal with noise, i.e. features of recorded audio orthogonal or detrimental to the recognition of the included speech. The goal of this project is to investigate a section of this problem by testing an ASR model on clean and dirty audio. A pretrained model was used with appropriate adjustments to fit the needs of the project. Recording data was augmented to add noise. By comparing the performance of models trained with noisy and clean audio in transcriptions of noisy audio, we were able to show that we obtained what we were expecting: WER = 0.289 when we fine-tune the model on noisy data, and WER = 0.500 when we fine-tune the model on clean audios. Thus, the ASR system partially ignores the added noise.

The dataset used was taken from the TIMIT dataset, a corpus containing recordings of read speech in American English, containing 5 hours of data (Garofolo et al. 1993) . The TIMIT dataset includes details such as phonetic detail, word detail, sentence type, dialect, and more; since these are not the focus of the project, they were removed during preprocessing. The fine-tuning and training was performed on an existing model, Wav2Vec2 (Baevski et al. 2020).

One of the complications that we incurred was that we aimed in the beginning to use a librspeech data set since it was filling our needs in terms of the development of the project since we were familiarised with its structure. However due to its data size, which was tremendously large, we had to switch from librispeech corpus to timit, but it went fine since we got a mitigation plan in case this will happen.

Moreover, generally, using a pretrained model for ASR applications is preferred. A pretrained model is generally trained to a point where it will perform well in general applications but wonâ€™t do very well in any specific task. The pretrained model can then be fine-tuned to perform best on specific tasks. For this project, we fine-tuned it using noisy training data to make it more robust at detecting and filtering out noise from clean audio samples.

We believe that the next iteration for this project to take it to the next level would be to pre-train the model on augmented data directly to perform in real world scenarios, where the noise is a dynamic variable, where we do not control the kind of noise nor the volume. But, in a realistic scenario this kind of work would need extensive resources and an extended time frame.

To sum up, we came up with the realisation while we were doing this project on how powerful this technology is in the real world environment. This kind of implementation has infinite applications in our daily life, such as speech-to-text conversion which can be used in, for instance, subtitles for youtube videos, real-time voice to text notes, improvement of speech recognition applications under higher amounts of noise, etc.
